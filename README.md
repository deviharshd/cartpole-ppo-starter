# CartPole PPO Starter

This project is a clean, self‑contained example of training and evaluating a Proximal Policy Optimization (PPO) agent on the classic CartPole‑v1 environment using Stable‑Baselines3 and Gymnasium.

## Contents

- `cartpole/`
  - `cartpole_ppo_train.py` – train PPO on CartPole‑v1.
  - `cartpole_ppo_infer.py` – watch the trained policy.
  - `cartpole_ppo.ipynb` – notebook walkthrough.
  - `cartpole_eval.py` – evaluation and summary stats.
  - `cartpole_record_video.py` – record CartPole runs to video.
- `notes/`
  - `rl_basics.md` – reinforcement learning fundamentals.
  - `ppo_explained.md` – PPO overview.
  - `experiment_template.md` – template for logging experiments.
- `images/`
  - `cartpole_graph.png` – training reward curve (generated by training).

## Setup

```bash
python -m venv .venv
source .venv/bin/activate      # Linux/macOS
# or
.venv\Scripts\activate         # Windows

python -m pip install --upgrade pip
python -m pip install -r requirements.txt
```

## Usage

Train PPO:

```bash
python cartpole/cartpole_ppo_train.py --timesteps 200000
```

Evaluate:

```bash
python cartpole/cartpole_eval.py --episodes 20
```

Record videos (requires `moviepy`):

```bash
python cartpole/cartpole_record_video.py --episodes 3
```

Visualize the trained agent:

```bash
python cartpole/cartpole_ppo_infer.py --episodes 5
```

## Demo Video

GitHub does not render `<video>` tags inside README files, so the embedded
player will not show up directly here. Instead, click the link (or image)
below to open the video on GitHub:

- [▶️ Watch CartPole PPO video](https://github.com/deviharshd/cartpole-ppo-starter/blob/main/videos/cartpole/cartpole_ppo-episode-0.mp4)

Or click the training curve thumbnail to open the same video:

[![CartPole PPO video](images/cartpole_graph.png)](https://github.com/deviharshd/cartpole-ppo-starter/blob/main/videos/cartpole/cartpole_ppo-episode-0.mp4)
